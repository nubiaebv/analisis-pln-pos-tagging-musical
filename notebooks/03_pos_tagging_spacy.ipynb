{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# POS Tagging con Spacy",
   "id": "6b0079edc3fe1562"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Instalación de Dependencias (Ejecutar primero)",
   "id": "a873e6b42c600ec2"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-02-18T22:39:25.648651700Z",
     "start_time": "2026-02-18T22:38:53.700223Z"
    }
   },
   "cell_type": "code",
   "source": [
    "!pip install -q nltk spacy pandas matplotlib seaborn\n",
    "\n",
    "# Descargar modelo de Spacy\n",
    "import subprocess\n",
    "import sys\n",
    "subprocess.check_call([sys.executable, \"-m\", \"spacy\", \"download\", \"en_core_web_sm\", \"-q\"])\n",
    "\n",
    "print(\"✅ Todas las dependencias instaladas correctamente\")"
   ],
   "id": "690f03778295a85b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 26.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Todas las dependencias instaladas correctamente\n"
     ]
    }
   ],
   "execution_count": 49
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1. Importar Librerías Necesarias",
   "id": "94e1b77fe0aef767"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T22:39:25.843193Z",
     "start_time": "2026-02-18T22:39:25.664870700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Importar todas las librerías necesarias\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from src.utils import path\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"✓ Librerías importadas correctamente\")"
   ],
   "id": "dca07df1b03e88b5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Librerías importadas correctamente\n"
     ]
    }
   ],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T22:39:33.095593300Z",
     "start_time": "2026-02-18T22:39:25.861423Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Descargar recursos necesarios de Spacy (si no están ya instalados)\n",
    "import spacy\n",
    "\n",
    "print(\"Cargando recursos de Spacy...\\n\")\n",
    "\n",
    "# Cargar modelo de Spacy en inglés\n",
    "print(\"Cargando modelo de Spacy...\")\n",
    "try:\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    print(\"✓ Modelo de Spacy cargado correctamente\")\n",
    "except OSError:\n",
    "    print(\"⚠ Modelo no encontrado. Instalando...\")\n",
    "    import subprocess\n",
    "    subprocess.run([\"python\", \"-m\", \"spacy\", \"download\", \"en_core_web_sm\"], check=True)\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    print(\"✓ Modelo de Spacy instalado y cargado\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"¡Listo para comenzar con el POS Tagging!\")\n",
    "print(\"=\"*60)"
   ],
   "id": "781c240844dcfe21",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando recursos de Spacy...\n",
      "\n",
      "Cargando modelo de Spacy...\n",
      "✓ Modelo de Spacy cargado correctamente\n",
      "\n",
      "============================================================\n",
      "¡Listo para comenzar con el POS Tagging!\n",
      "============================================================\n"
     ]
    }
   ],
   "execution_count": 51
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Carga del Corpus",
   "id": "b3e2b91d15d1eacf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T22:39:34.350510800Z",
     "start_time": "2026-02-18T22:39:33.339549Z"
    }
   },
   "cell_type": "code",
   "source": [
    "directorio_proyecto = path.obtener_ruta_local()\n",
    "df = pd.read_csv(directorio_proyecto+'\\\\data\\\\processed\\\\corpus_canciones.csv',delimiter = ',',decimal = \".\", encoding='utf-8')\n",
    "df.head()"
   ],
   "id": "3518c418a9a42b93",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "          Artist          nombre_cancion  \\\n",
       "0  Ariana Grande          ​thank u, next   \n",
       "1  Ariana Grande                 7 rings   \n",
       "2  Ariana Grande         ​God is a woman   \n",
       "3  Ariana Grande            Side To Side   \n",
       "4  Ariana Grande  ​​no tears left to cry   \n",
       "\n",
       "                                       letra_cancion  Periodo Genero  \n",
       "0  thought i'd end up with sean but he wasn't a m...   2018.0    pop  \n",
       "1  yeah breakfast at tiffany's and bottles of bub...   2019.0    pop  \n",
       "2  you you love it how i move you you love it how...   2018.0    pop  \n",
       "3  ariana grande  nicki minaj i've been here all ...   2016.0    pop  \n",
       "4  right now i'm in a state of mind i wanna be in...   2018.0    pop  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Artist</th>\n",
       "      <th>nombre_cancion</th>\n",
       "      <th>letra_cancion</th>\n",
       "      <th>Periodo</th>\n",
       "      <th>Genero</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ariana Grande</td>\n",
       "      <td>​thank u, next</td>\n",
       "      <td>thought i'd end up with sean but he wasn't a m...</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>pop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ariana Grande</td>\n",
       "      <td>7 rings</td>\n",
       "      <td>yeah breakfast at tiffany's and bottles of bub...</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>pop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ariana Grande</td>\n",
       "      <td>​God is a woman</td>\n",
       "      <td>you you love it how i move you you love it how...</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>pop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ariana Grande</td>\n",
       "      <td>Side To Side</td>\n",
       "      <td>ariana grande  nicki minaj i've been here all ...</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>pop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ariana Grande</td>\n",
       "      <td>​​no tears left to cry</td>\n",
       "      <td>right now i'm in a state of mind i wanna be in...</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>pop</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 52
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2. POS Tagging con Spacy",
   "id": "8d390158e55eb0bf"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Tokenización",
   "id": "9132fc09fc639e2c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T22:45:35.689125600Z",
     "start_time": "2026-02-18T22:39:34.747106Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def realizar_token(letra):\n",
    "    doc = nlp(letra)\n",
    "    token = []\n",
    "    for tok in doc:\n",
    "        tokens = tok.text\n",
    "        token.append(tokens)\n",
    "    return token\n",
    "\n",
    "tqdm.pandas(desc=\"Paso 1 Tokenización\")\n",
    "df['tokens'] = df['letra_cancion'].progress_apply(realizar_token)"
   ],
   "id": "99ca85f63b22c82d",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Paso 1 Tokenización: 100%|██████████| 5205/5205 [06:00<00:00, 14.43it/s]\n"
     ]
    }
   ],
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T22:45:36.624726500Z",
     "start_time": "2026-02-18T22:45:36.514210Z"
    }
   },
   "cell_type": "code",
   "source": "df",
   "id": "ce4daae7a0217385",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "             Artist                                     nombre_cancion  \\\n",
       "0     Ariana Grande                                     ​thank u, next   \n",
       "1     Ariana Grande                                            7 rings   \n",
       "2     Ariana Grande                                    ​God is a woman   \n",
       "3     Ariana Grande                                       Side To Side   \n",
       "4     Ariana Grande                             ​​no tears left to cry   \n",
       "...             ...                                                ...   \n",
       "5200   Taylor Swift  Should’ve Said No (Live from Clear Channel Str...   \n",
       "5201   Taylor Swift  Teardrops on my Guitar (Live from Clear Channe...   \n",
       "5202   Taylor Swift                                 Evermore [Forward]   \n",
       "5203   Taylor Swift                  Tolerate it (Polskie Tłumaczenie)   \n",
       "5204   Taylor Swift                                           Find you   \n",
       "\n",
       "                                          letra_cancion  Periodo Genero  \\\n",
       "0     thought i'd end up with sean but he wasn't a m...   2018.0    pop   \n",
       "1     yeah breakfast at tiffany's and bottles of bub...   2019.0    pop   \n",
       "2     you you love it how i move you you love it how...   2018.0    pop   \n",
       "3     ariana grande  nicki minaj i've been here all ...   2016.0    pop   \n",
       "4     right now i'm in a state of mind i wanna be in...   2018.0    pop   \n",
       "...                                                 ...      ...    ...   \n",
       "5200  it's strange to think the songs we used to sin...   2008.0    pop   \n",
       "5201  drew looks at me i fake a smile so he won't se...   2008.0    pop   \n",
       "5202  to put it plainly we just couldnt stop writing...   2020.0    pop   \n",
       "5203  zwrotka  siedzę i patrzę jak czytasz z głową p...   2020.0    pop   \n",
       "5204  trying just like they say just taking the step...   2024.0    pop   \n",
       "\n",
       "                                                 tokens  \n",
       "0     [thought, i, 'd, end, up, with, sean, but, he,...  \n",
       "1     [yeah, breakfast, at, tiffany, 's, and, bottle...  \n",
       "2     [you, you, love, it, how, i, move, you, you, l...  \n",
       "3     [ariana, grande,  , nicki, minaj, i, 've, been...  \n",
       "4     [right, now, i, 'm, in, a, state, of, mind, i,...  \n",
       "...                                                 ...  \n",
       "5200  [it, 's, strange, to, think, the, songs, we, u...  \n",
       "5201  [drew, looks, at, me, i, fake, a, smile, so, h...  \n",
       "5202  [to, put, it, plainly, we, just, could, nt, st...  \n",
       "5203  [zwrotka,  , siedzę, i, patrzę, jak, czytasz, ...  \n",
       "5204  [trying, just, like, they, say, just, taking, ...  \n",
       "\n",
       "[5205 rows x 6 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Artist</th>\n",
       "      <th>nombre_cancion</th>\n",
       "      <th>letra_cancion</th>\n",
       "      <th>Periodo</th>\n",
       "      <th>Genero</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ariana Grande</td>\n",
       "      <td>​thank u, next</td>\n",
       "      <td>thought i'd end up with sean but he wasn't a m...</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>pop</td>\n",
       "      <td>[thought, i, 'd, end, up, with, sean, but, he,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ariana Grande</td>\n",
       "      <td>7 rings</td>\n",
       "      <td>yeah breakfast at tiffany's and bottles of bub...</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>pop</td>\n",
       "      <td>[yeah, breakfast, at, tiffany, 's, and, bottle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ariana Grande</td>\n",
       "      <td>​God is a woman</td>\n",
       "      <td>you you love it how i move you you love it how...</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>pop</td>\n",
       "      <td>[you, you, love, it, how, i, move, you, you, l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ariana Grande</td>\n",
       "      <td>Side To Side</td>\n",
       "      <td>ariana grande  nicki minaj i've been here all ...</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>pop</td>\n",
       "      <td>[ariana, grande,  , nicki, minaj, i, 've, been...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ariana Grande</td>\n",
       "      <td>​​no tears left to cry</td>\n",
       "      <td>right now i'm in a state of mind i wanna be in...</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>pop</td>\n",
       "      <td>[right, now, i, 'm, in, a, state, of, mind, i,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5200</th>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>Should’ve Said No (Live from Clear Channel Str...</td>\n",
       "      <td>it's strange to think the songs we used to sin...</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>pop</td>\n",
       "      <td>[it, 's, strange, to, think, the, songs, we, u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5201</th>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>Teardrops on my Guitar (Live from Clear Channe...</td>\n",
       "      <td>drew looks at me i fake a smile so he won't se...</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>pop</td>\n",
       "      <td>[drew, looks, at, me, i, fake, a, smile, so, h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5202</th>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>Evermore [Forward]</td>\n",
       "      <td>to put it plainly we just couldnt stop writing...</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>pop</td>\n",
       "      <td>[to, put, it, plainly, we, just, could, nt, st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5203</th>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>Tolerate it (Polskie Tłumaczenie)</td>\n",
       "      <td>zwrotka  siedzę i patrzę jak czytasz z głową p...</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>pop</td>\n",
       "      <td>[zwrotka,  , siedzę, i, patrzę, jak, czytasz, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5204</th>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>Find you</td>\n",
       "      <td>trying just like they say just taking the step...</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>pop</td>\n",
       "      <td>[trying, just, like, they, say, just, taking, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5205 rows × 6 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 54
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Etiquetado POS",
   "id": "c2c3ec5bd4a61eb2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2026-02-18T22:45:37.055801300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def realizar_etiquetado(tokens_lista):\n",
    "    \"\"\"\n",
    "    Recibe una lista de tokens (strings) y devuelve tuplas (token, tag)\n",
    "    \"\"\"\n",
    "    # Reconstruir el texto y procesarlo con spaCy\n",
    "    texto = \" \".join(tokens_lista)\n",
    "    doc = nlp(texto)\n",
    "    etiquetas = [(token.text, token.pos_) for token in doc]\n",
    "    return etiquetas\n",
    "\n",
    "tqdm.pandas(desc=\"Paso 2: Etiquetado POS\")\n",
    "df['Etiquetado_POS'] = df['tokens'].progress_apply(realizar_etiquetado)"
   ],
   "id": "d469dbcff9cfc80e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Paso 2: Etiquetado POS:  60%|██████    | 3141/5205 [04:57<02:26, 14.13it/s] "
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df",
   "id": "25a83dfd2bd37275",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Borrado de StopWords y NER",
   "id": "bba0b6afab0bf3d6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def eliminar_stopwords(etiquetas_pos):\n",
    "    \"\"\"\n",
    "    Recibe una lista de tuplas (token, tag) y elimina las stopwords\n",
    "    \"\"\"\n",
    "    sin_stopwords = [(token, tag) for token, tag in etiquetas_pos\n",
    "                     if token.lower() not in nlp.Defaults.stop_words]\n",
    "    return sin_stopwords\n",
    "\n",
    "tqdm.pandas(desc=\"Paso 3: Eliminar Stopwords\")\n",
    "df['StopWords'] = df['Etiquetado_POS'].progress_apply(eliminar_stopwords)"
   ],
   "id": "2f398eb978b1c659",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df",
   "id": "318b91a2c88d1762",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Mayúsculas y minúsculas",
   "id": "316f93bd6815a5ed"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def aplicar_minusculas(etiquetas_pos):\n",
    "    \"\"\"\n",
    "    Recibe lista de tuplas (token, tag) y convierte tokens a minúsculas\n",
    "    \"\"\"\n",
    "    minusculas = [(token.lower(), tag) for token, tag in etiquetas_pos]\n",
    "    return minusculas\n",
    "\n",
    "tqdm.pandas(desc=\"Paso 4: Aplicar Minúsculas\")\n",
    "df['Minusculas'] = df['StopWords'].progress_apply(aplicar_minusculas)"
   ],
   "id": "abe172409543a317",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df",
   "id": "dd4b7e8a43337bec",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Lematización",
   "id": "e372d9e71f91f213"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def aplicar_lematizacion(tuplas_tokens):\n",
    "    \"\"\"\n",
    "    Recibe lista de tuplas (token, tag) y devuelve (lemma, tag)\n",
    "    \"\"\"\n",
    "    # Reconstruir el texto desde las tuplas\n",
    "    texto = \" \".join([token for token, tag in tuplas_tokens])\n",
    "    doc = nlp(texto)\n",
    "\n",
    "    # Obtener lemmas con sus tags\n",
    "    lemas = [(token.lemma_, token.tag_) for token in doc]\n",
    "    return lemas\n",
    "\n",
    "tqdm.pandas(desc=\"Paso 5: Lematización\")\n",
    "df['Lematizado'] = df['Minusculas'].progress_apply(aplicar_lematizacion)"
   ],
   "id": "9022e04dd5c4f52d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df",
   "id": "5e9ba7ac9f8828b3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ============================================================================\n",
    "# VISUALIZACIÓN DE DISTRIBUCIÓN DE POS TAGS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"VISUALIZACIÓN DE DISTRIBUCIÓN DE POS TAGS\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "# Recolectar TODOS los POS tags de todas las canciones\n",
    "def extraer_todos_pos_tags(df, columna_pos='Lematizado'):\n",
    "   todos_tags = []\n",
    "   for pos_tags_list in df[columna_pos]:\n",
    "        for tupla in pos_tags_list:\n",
    "            tag = tupla[1]  # El segundo elemento es el tag\n",
    "            todos_tags.append(tag)\n",
    "        return todos_tags\n",
    "\n",
    "# Extraer todos los tags\n",
    "print(\"Extrayendo POS tags de todas las canciones...\")\n",
    "todos_pos_tags = extraer_todos_pos_tags(df, 'Lematizado')\n",
    "\n",
    "# Contar frecuencias\n",
    "pos_counts = Counter(todos_pos_tags)\n",
    "\n",
    "# Ordenar por frecuencia (mayor a menor)\n",
    "pos_counts_sorted = dict(sorted(pos_counts.items(), key=lambda x: x[1], reverse=True))\n",
    "\n",
    "print(f\"✓ Total de palabras analizadas: {len(todos_pos_tags):,}\")\n",
    "print(f\"✓ Tipos de POS tags encontrados: {len(pos_counts)}\")\n",
    "\n",
    "# Visualización\n",
    "fig, ax = plt.subplots(figsize=(14, 7))\n",
    "\n",
    "pos_names = list(pos_counts_sorted.keys())\n",
    "pos_values = list(pos_counts_sorted.values())\n",
    "\n",
    "colors = plt.cm.Set3(range(len(pos_names)))\n",
    "bars = ax.bar(pos_names, pos_values, color=colors, edgecolor='black', linewidth=1.5)\n",
    "\n",
    "# Agregar valores en las barras\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "            f'{int(height):,}',\n",
    "            ha='center', va='bottom', fontweight='bold', fontsize=9)\n",
    "\n",
    "ax.set_xlabel('Categoría Gramatical (POS)', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('Frecuencia', fontsize=12, fontweight='bold')\n",
    "ax.set_title(f'Distribución de Etiquetas POS en {len(df):,} Canciones',\n",
    "             fontsize=14, fontweight='bold')\n",
    "ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "\n",
    "# Rotar etiquetas si hay muchas\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Mostrar estadísticas\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ESTADÍSTICAS DE POS TAGS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\n Total de palabras (después de normalización): {len(todos_pos_tags):,}\")\n",
    "print(f\" Tipos diferentes de POS tags: {len(pos_counts)}\")\n",
    "\n",
    "print(\"\\n TOP 10 POS TAGS MÁS FRECUENTES:\")\n",
    "for i, (tag, count) in enumerate(list(pos_counts_sorted.items())[:10], 1):\n",
    "    porcentaje = (count / len(todos_pos_tags)) * 100\n",
    "    print(f\"{i:2}. {tag:5} → {count:8,} ocurrencias ({porcentaje:5.2f}%)\")"
   ],
   "id": "12ad3ab58e43b986",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Guardar Corpus",
   "id": "686c436fc066a7fb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df.to_csv(directorio_proyecto+'\\\\data\\\\results\\\\corpus_canciones_spicy.csv', index=False)",
   "id": "ce3b239a223f0021",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
